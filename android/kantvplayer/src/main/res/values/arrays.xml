<?xml version="1.0" encoding="utf-8"?>
<resources>
    <string-array name="cpu_thread_num_entries">
        <item>1 threads</item>
        <item>2 threads</item>
        <item>4 threads</item>
        <item>8 threads</item>
    </string-array>
    <string-array name="cpu_thread_num_values">
        <item>1</item>
        <item>2</item>
        <item>4</item>
        <item>8</item>
    </string-array>
    <string-array name="cpu_power_mode_entries">
        <item>HIGH(only big cores)</item>
        <item>LOW(only LITTLE cores)</item>
        <item>FULL(all cores)</item>
        <item>NO_BIND(depends on system)</item>
        <item>RAND_HIGH</item>
        <item>RAND_LOW</item>
    </string-array>
    <string-array name="cpu_power_mode_values">
        <item>LITE_POWER_HIGH</item>
        <item>LITE_POWER_LOW</item>
        <item>LITE_POWER_FULL</item>
        <item>LITE_POWER_NO_BIND</item>
        <item>LITE_POWER_RAND_HIGH</item>
        <item>LITE_POWER_RAND_LOW</item>
    </string-array>

    <string-array name="encodeFormat">
        <item>H264</item>
        <item>H265</item>
        <item>H266</item>
        <item>Intel-AV1</item>
        <item>Google-AV1</item>
    </string-array>


    <string-array name="encodeResolution">
        <item>352x288  (CIF)</item>
        <item>640x480  (VGA)</item>
        <item>720x576  (DVD)</item>
        <item>1280x720 (720P)</item>
        <item>1920x1080(1080P)</item>
        <item>2560x1440(2K)</item>
        <item>3840x2160(4K)</item>
        <item>7680x4320(8K)</item>
    </string-array>

    <string-array name="encodePattern">
        <item>triangle</item>
        <item>square</item>
    </string-array>

    <string-array name="encodeFilter">
        <item>save to file</item>
        <item>not save</item>
    </string-array>

    <string-array name="benchType">
        <item>memcpy</item>                 <!-- memcopy benchmark -->
        <item>mulmat</item>                 <!-- mulmat benchmark -->
        <item>ASR</item>                    <!-- ASR(whisper.cpp based on ggml)benchmark -->
        <item>LLM</item>                    <!-- LLM(llama.cpp based on ggml)benchmark -->
    </string-array>

    <string-array name="threadCounts">
        <item>8</item>
        <item>7</item>
        <item>6</item>
        <item>5</item>
        <item>4</item>
        <item>3</item>
        <item>2</item>
        <item>1</item>
    </string-array>

    <string-array name="modelName">
        <item>tiny</item>
        <item>tiny.en</item>
        <item>tiny.en-q5_1</item>
        <item>tiny.en-q8_0</item>
        <item>tiny-q5_1</item>
        <item>base</item>
        <item>base.en</item>
        <item>base-q5_1</item>
        <item>small</item>
        <item>small.en</item>
        <item>small.en-q5_1</item>
        <item>small-q5_1</item>
        <item>medium</item>
        <item>medium.en</item>
        <item>medium.en-q5_0</item>
        <item>large</item>
        <item>llama2-7b</item>
        <item>qwen_8b</item>
        <item>baichuan2-7b</item>
        <item>gemma-2b.Q8_0</item>
        <item>yi-chat-6b</item>
        <item>minicpm-v</item>
        <item>text2image</item>
        <item>mnist</item>
        <item>tts-small</item>
    </string-array>

    <string-array name="backendtype">
        <!--
        TODO: the existing implementation of ggml-hexagon.cpp can't cover following special case:
              toggle backend and forth between QNN-NPU and cDSP and ggml in a standard Android APP or in
              a same running process
              supportive of such special case is easy but it will significantly increase the size of APK
        -->
        <!--
        <item>QNN-CPU</item>
        <item>QNN-GPU</item>
        <item>QNN-NPU</item>
        -->
        <item>cDSP</item>
        <item>ggml</item>
    </string-array>

    <string-array name="hwacceltype">
        <item>QNN</item>
        <item>QNN-SINGLEGRAPH</item>
        <item>cDSP</item>
    </string-array>

    <string-array name="optype">
        <item>add</item>
        <item>mul</item>
        <item>mulmat</item>
    </string-array>

    <string-array name="graphtype">
        <item>mnist</item>
        <item>inception</item>
    </string-array>


    <string-array name="scrfd_model_array">
        <item>500m</item>
        <item>500m_kps</item>
        <item>1g</item>
        <item>2.5g</item>
        <item>2.5g_kps</item>
        <item>10g</item>
        <item>10g_kps</item>
    </string-array>

    <string-array name="nanodat_model_array">
        <item>m</item>
        <item>m-416</item>
        <item>g</item>
        <item>ELite0_320</item>
        <item>ELite1_416</item>
        <item>ELite2_512</item>
        <item>RepVGG</item>
    </string-array>

    <string-array name="ncnn_backend">
        <item>CPU</item>
        <item>GPU</item>
    </string-array>

    <string-array name="ncnn_realtimeinference_netid">
        <item>scrfd</item>
        <item>nanodat</item>
        <item>yolov10</item>
    </string-array>

</resources>
